---
---
@inproceedings{lai-king-paroubek-2024-pre,
    title = "Pre-training data selection for biomedical domain adaptation using journal impact metrics",
    author = "Lai-king, Mathieu  and
      Paroubek, Patrick",
    editor = "Demner-Fushman, Dina  and
      Ananiadou, Sophia  and
      Miwa, Makoto  and
      Roberts, Kirk  and
      Tsujii, Junichi",
    booktitle = "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bionlp-1.27",
    pages = "363--369",
    abstract = "Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular publication of numerous scientific articles. PubMed, a significant corpus of text, is frequently used in the biomedical domain. The primary objective of this study is to explore whether refining a pre-training dataset using specific quality metrics for scientific papers can enhance the performance of the resulting model. To accomplish this, we employ two straightforward journal impact metrics and conduct experiments by continually pre-training BERT on various subsets of the complete PubMed training set, we then evaluate the resulting models on biomedical language understanding tasks from the BLURB benchmark. Our results show that pruning using journal impact metrics is not efficient. But we also show that pre-training using fewer abstracts (but with the same number of training steps) does not necessarily decrease the resulting model{'}s performance.",
    preview={acl2024-logo.jpg},
    abbr="BioNLP@ACL2024",
}

@inproceedings{raithel:hal-04297589,
  TITLE = {{KEEPHA at n2c2 2022: Track 1}},
  AUTHOR = {Raithel, Lisa and Mutinda,, Faith W. and Andrade, Gabriel H. B. and Yeh, Hui-Syuan and Nishiyama, Tomohiro and La{\"i}-King, Mathieu and Yada, Shuntaro and Roller, Roland and Grouin, Cyril and Savary, Agata and N{\'e}v{\'e}ol, Aur{\'e}lie and Lavergne, Thomas and Aramaki, Eiji and M{\"o}ller, Sebastian and Matsumoto, Yuji and Zweigenbaum, Pierre},
  URL = {https://hal.science/hal-04297589},
  BOOKTITLE = {{2022 n2c2 Shared Task and Workshop at AMIA Fall Symposium}},
  ADDRESS = {Washington, DC, United States},
  YEAR = {2022},
  MONTH = Nov,
  PDF = {https://hal.science/hal-04297589/file/keepha_n2c2_track1.pdf},
  HAL_ID = {hal-04297589},
  HAL_VERSION = {v1},
  abbr="n2c2 2022",
}

@inproceedings{laiking-paroubek-2025,
    title = "Évaluation de la qualité de rapport des essais cliniques avec des larges modèles de langue [Evaluation of Clinical Trials Reporting Quality using Large Language Models]",
    author = "Laï-king, Mathieu  and Paroubek, Patrick",
    editor = "Boudin, Florian and Aizawa, Akiko",
    booktitle = "Traitement Automatique des Langues, Volume 65, Num{\'e}ro 2 : Numéro spécial sur le Traitement automatique de documents scientifiques [Scientific Documents Processing]",
    year = "2025",
    address = "France",
    publisher = "ATALA (Association pour le Traitement Automatique des Langues)",
    url = "https://www.atala.org/numeros-tal/2024",
    pages = "13--38",
    language = "fra",
    abbr="TAL 65-2",
    preview={atala-logo.png}
}
